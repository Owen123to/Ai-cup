{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "bb173248",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "# from tensorflow.keras.layers import Conv2D, ReLU, Flatten, Dense, Softmax, BatchNormalization, Input, ZeroPadding2D, Activation\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.optimizers import Adam, Nadam, SGD\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "\n",
    "import keras\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "62384345",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__\n",
    "tf.test.is_gpu_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd95ed0c",
   "metadata": {},
   "source": [
    "# Data Pre-Processing\n",
    "\n",
    "Open **kyu_train.csv** file and split the games into a list.\n",
    "Every row of csv: `KL0000000001,B,B[pq],W[dd],B[dp],W[pd],B[jc],...`. \n",
    "\n",
    "Columns are:\n",
    "\n",
    "    1. KL0000000001: Game ID\n",
    "    2. B: Player's color\n",
    "    3-... : Moves\n",
    "    \n",
    "We cropped only the moves to game list as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2f8872fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = open('./Training Dataset/kyu_train.csv').read().splitlines()\n",
    "games = [i.split(',',2)[-1] for i in df]\n",
    "colors = [i.split(',',2)[1] for i in df]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58532b01",
   "metadata": {},
   "source": [
    "Create a dictionary to convert the coordinates from characters to numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "496585f2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': 0,\n",
       " 'b': 1,\n",
       " 'c': 2,\n",
       " 'd': 3,\n",
       " 'e': 4,\n",
       " 'f': 5,\n",
       " 'g': 6,\n",
       " 'h': 7,\n",
       " 'i': 8,\n",
       " 'j': 9,\n",
       " 'k': 10,\n",
       " 'l': 11,\n",
       " 'm': 12,\n",
       " 'n': 13,\n",
       " 'o': 14,\n",
       " 'p': 15,\n",
       " 'q': 16,\n",
       " 'r': 17,\n",
       " 's': 18}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chars = 'abcdefghijklmnopqrs'\n",
    "coordinates = {k:v for v,k in enumerate(chars)}\n",
    "chartonumbers = {k:v for k,v in enumerate(chars)}\n",
    "coordinates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92277370",
   "metadata": {},
   "source": [
    "We decided to build a DCNN model in this tutorial. We create data samples by using every move in every game, meaning that the target is to predict the next move by feeding the previous state of the table in every game for every move. Therefore, we can collect much more data samples from games.\n",
    "\n",
    "For the simplicity, we used 4 dimensional feature map to represent the data as below:\n",
    " 1. Positions of black stones: mark them as 1 and the rest of the table as 0\n",
    " 2. Positions of white stones: mark them as 1 and the rest of the table as 0\n",
    " 3. Empty areas of the table: mark the empty areas as 1 and occupied areas as 0\n",
    " 4. The last move in the table: mark the position of the last move as 1 and the rest as 0\n",
    " \n",
    "Target value is a number between 0-361(19\\*19). Later this will be one-hot encoded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0adb423c",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (364411018.py, line 9)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[47], line 9\u001b[1;36m\u001b[0m\n\u001b[1;33m    if(len(moves) == 0)\u001b[0m\n\u001b[1;37m                       ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "#0:所有跟最後一步顏色相同的\n",
    "#1:所有跟最後一步顏色不同的\n",
    "#2:標示空地\n",
    "#3~10:最後8步\n",
    "#11:周圍黑棋7*7\n",
    "#12:周圍白棋7*7\n",
    "def prepare_input(moves):\n",
    "    x = np.zeros((19,19,13))\n",
    "    if(len(moves) == 0)\n",
    "        return x;\n",
    "    player_color = moves[-1][0] #\n",
    "    for move in moves:\n",
    "        color = move[0]\n",
    "        column = coordinates[move[2]]\n",
    "        row = coordinates[move[3]]\n",
    "        if color == player_color: #\n",
    "            x[row,column,0] = 1\n",
    "            x[row,column,2] = 1\n",
    "        else: #\n",
    "            x[row,column,1] = 1\n",
    "            x[row,column,2] = 1\n",
    "    x[:,:,2] = np.where(x[:,:,2] == 0, 1, 0)\n",
    "    \n",
    "    #倒數8步\n",
    "    sz = len(moves)\n",
    "    last1 = sz - 1\n",
    "    last8 = max(sz - 9, 0)\n",
    "    for i in range(last1, last8, -1):\n",
    "        col = coordinates[moves[i][2]]\n",
    "        row = coordinates[moves[i][3]]\n",
    "        x[row, col, 11 - (sz - i)] = 1\n",
    "    \n",
    "    #周圍7*7\n",
    "    last_col = coordinates[moves[-1][2]]\n",
    "    last_row = coordinates[moves[-1][3]]\n",
    "    rad = 3 #要改範圍大小的話改這個\n",
    "    row1 = max(0, last_row - rad)\n",
    "    row7 = min(18, last_row + rad)\n",
    "    col1 = max(0, last_col - rad)\n",
    "    col7 = min(18, last_col + rad)\n",
    "    for i in range(row1, row7 + 1, 1):\n",
    "        for j in range(col1, col7 + 1, 1):\n",
    "            x[i, j, 11] = x[i, j, 1]\n",
    "            x[i, j, 12] = x[i, j, 2]\n",
    "            \n",
    "    #列印所有棋盤\n",
    "#     for i in range(0, 3, 1):\n",
    "#         print(\"  a b c d e f g h i j k l m n o p q r s\")\n",
    "#         for j in range(0, 19, 1):\n",
    "#             print(chars[j], end = \" \")\n",
    "#             for k in range(0, 19, 1):\n",
    "#                 print(int(x[j, k, i]), end = \" \")\n",
    "#             print(\"\")\n",
    "#         print(\"\")\n",
    "    \n",
    "    return x\n",
    "def prepare_label(move):\n",
    "    column = coordinates[move[2]]\n",
    "    row = coordinates[move[3]]\n",
    "    return column*19+row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "758808ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Games: 118500, Total Moves: 27135638\n"
     ]
    }
   ],
   "source": [
    "# Check how many samples can be obtained\n",
    "n_games = 0\n",
    "n_moves = 0\n",
    "for game in games:\n",
    "    n_games += 1\n",
    "    moves_list = game.split(',')\n",
    "    for move in moves_list:\n",
    "        n_moves += 1\n",
    "print(f\"Total Games: {n_games}, Total Moves: {n_moves}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46403360",
   "metadata": {},
   "source": [
    "The code below is run for baseline model only by using only the first 500 games from the dataset. You might need to create a data generator to use complete dataset. Otherwise your RAM might not enough to store all (If you run the code on free version of Google Colab, it will crash above 500 game samples)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a9bb0ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_generator(games, batch_size):\n",
    "    def generator():\n",
    "        x_batch = [] # Initialize data batch\n",
    "        y_batch = [] # Initialize target batch\n",
    "        for game_i, game in enumerate(games): # Iterate through games\n",
    "            moves_list = game.split(',')\n",
    "#             print(moves_list)\n",
    "            for count, move in enumerate(moves_list):\n",
    "                if colors[game_i] == move[0]:\n",
    "#                     print(move)\n",
    "                    x_batch.append(prepare_input(moves_list[:count]))\n",
    "                    y_batch.append(prepare_label(moves_list[count]))\n",
    "                    if len(x_batch) == batch_size: # Yield when reached batch size\n",
    "                        yield np.array(x_batch), tf.one_hot(np.array(y_batch), depth=19*19)\n",
    "                        x_batch = []\n",
    "                        y_batch = []\n",
    "    return generator\n",
    "\n",
    "batch_size = 128\n",
    "val_rate = 0.3 # 0.1 means 0.1 for val ,0.9 for training\n",
    "split_point = int(len(games) * (1 - val_rate))\n",
    "generator = data_generator(games[:split_point], batch_size)\n",
    "dataset = tf.data.Dataset.from_generator(generator, \n",
    "                                         output_types=(tf.float32, tf.float32),\n",
    "                                         output_shapes=(tf.TensorShape((batch_size,19,19,13)),tf.TensorShape((batch_size,361)))\n",
    "                                        )\n",
    "# SHUFFLE_BUFFER_SIZE = 200\n",
    "# dataset = dataset.shuffle(SHUFFLE_BUFFER_SIZE).batch(batch_size)\n",
    "dataset = dataset.prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5b2392a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_generator = data_generator(games[:split_point], batch_size)\n",
    "val_dataset = tf.data.Dataset.from_generator(val_generator, \n",
    "                                         output_types=(tf.float32, tf.float32),\n",
    "                                         output_shapes=(tf.TensorShape((batch_size,19,19,13)),tf.TensorShape((batch_size,361)))\n",
    "                                        )\n",
    "# SHUFFLE_BUFFER_SIZE = 200\n",
    "# dataset = dataset.shuffle(SHUFFLE_BUFFER_SIZE).batch(batch_size)\n",
    "val_dataset = dataset.prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b9c5de9",
   "metadata": {},
   "source": [
    "# Training\n",
    "\n",
    "### Simple DCNN Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "dd4cb23d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def identity_block(input_tensor, kernel_size, filters, stage, block):\n",
    "    filters1, filters2, filters3 = filters\n",
    "    bn_axis = -1\n",
    "    \n",
    "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
    "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
    "    # 這邊就是圖5上的1x1x64降維操作，假設input x的維度是(n, n, 256), channel last\n",
    "    x = layers.Conv2D(filters1, (1, 1),\n",
    "#                       kernel_initializer='he_normal',\n",
    "                      name=conv_name_base + '2a')(input_tensor)\n",
    "    x = layers.BatchNormalization(axis=bn_axis, name=bn_name_base + '2a')(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "    \n",
    "    # 正常的3x3x64卷積操作，Feature Map長寬仍是n x n\n",
    "    x = layers.Conv2D(filters2, kernel_size,\n",
    "                      padding='same',\n",
    "#                       kernel_initializer='he_normal',\n",
    "                      name=conv_name_base + '2b')(x)\n",
    "    x = layers.BatchNormalization(axis=bn_axis, name=bn_name_base + '2b')(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "    \n",
    "    # 最後升維到256，維度(n,n,256) -> 變成可以和(Indentity)input x相加的維度\n",
    "    x = layers.Conv2D(filters3, (1, 1),\n",
    "#                       kernel_initializer='he_normal',\n",
    "                      name=conv_name_base + '2c')(x)\n",
    "    x = layers.BatchNormalization(axis=bn_axis, name=bn_name_base + '2c')(x)\n",
    "    \n",
    "    # 相加後做non-linear轉換\n",
    "    x = layers.add([x, input_tensor])\n",
    "    x = layers.Activation('relu')(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "208834da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_block(input_tensor,\n",
    "               kernel_size,\n",
    "               filters,\n",
    "               stage,\n",
    "               block,\n",
    "               strides=(1, 1)):\n",
    "    filters1, filters2, filters3 = filters\n",
    "    bn_axis = -1\n",
    "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
    "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
    "    \n",
    "    # 因為是projection shortcut 所以input的x可能跟output維度不同\n",
    "    # input維度(n,n,256) -->降維 (n,n,64)\n",
    "    # 如果Strides有改，則利用Strides來改變Feature Map長寬\n",
    "    x = layers.Conv2D(filters1, (1, 1), strides=strides,  \n",
    "#                       kernel_initializer='he_normal',\n",
    "                      name=conv_name_base + '2a')(input_tensor)\n",
    "    x = layers.BatchNormalization(axis=bn_axis, name=bn_name_base + '2a')(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "    \n",
    "    # (3,3)的kernel, padding都pad好pad滿，不改變Feature Map尺寸大小\n",
    "    x = layers.Conv2D(filters2, kernel_size, padding='same', \n",
    "#                       kernel_initializer='he_normal',\n",
    "                      name=conv_name_base + '2b')(x)\n",
    "    x = layers.BatchNormalization(axis=bn_axis, name=bn_name_base + '2b')(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "    \n",
    "    # 用1x1 conv升維到假設512\n",
    "    x = layers.Conv2D(filters3, (1, 1), \n",
    "#                       kernel_initializer='he_normal',\n",
    "                      name=conv_name_base + '2c')(x)\n",
    "    x = layers.BatchNormalization(axis=bn_axis, name=bn_name_base + '2c')(x)\n",
    "    \n",
    "    # 因input維度是256，這邊就需要做projectr將維度升到512相加\n",
    "    shortcut = layers.Conv2D(filters3, (1, 1), strides=strides,\n",
    "#                              kernel_initializer='he_normal',\n",
    "                             name=conv_name_base + '1')(input_tensor)\n",
    "    shortcut = layers.BatchNormalization(\n",
    "        axis=bn_axis, name=bn_name_base + '1')(shortcut)\n",
    "    # F(x) + x(升維後的x)\n",
    "    x = layers.add([x, shortcut])\n",
    "    x = layers.Activation('relu')(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "2ca25ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ResNet50(include_top=True,\n",
    "             input_tensor=None,\n",
    "             input_shape=None,\n",
    "             pooling=False):\n",
    "    img_input = layers.Input(shape = input_shape)\n",
    "    bn_axis = -1 #unknow\n",
    "    ##### optional\n",
    "#     x = layers.ZeroPadding2D(padding=(3, 3), name='conv1_pad')(img_input)\n",
    "#     x = layers.Conv2D(32, (7, 7),\n",
    "#                       strides=(2, 2),\n",
    "#                       padding='same',\n",
    "#                       kernel_initializer='he_normal',\n",
    "#                       name='conv1')(img_input)\n",
    "#     x = layers.BatchNormalization(axis=bn_axis, name='bn_conv1')(x)\n",
    "#     x = layers.Activation('relu')(x)\n",
    "    #####\n",
    "    \n",
    "    x = conv_block(img_input, 3, [64, 64, 256], stage=2, block='a', strides=(1, 1))  # input Channel大小會跟最後最後residual output尺寸一樣\n",
    "    x = identity_block(x, 3, [64, 64, 256], stage=2, block='b')\n",
    "    x = identity_block(x, 3, [64, 64, 256], stage=2, block='c')\n",
    "    # 256-d to 512-d\n",
    "#     x = conv_block(x, 3, [64, 64, 256], stage=3, block='a') # projection shortcut\n",
    "    x = identity_block(x, 3, [64,64, 256], stage=3, block='b')\n",
    "    x = identity_block(x, 3, [64, 64, 256], stage=3, block='c')\n",
    "    x = identity_block(x, 3, [64, 64, 256], stage=3, block='d')\n",
    "    # 512-d to 1024-d\n",
    "#     x = conv_block(x, 3, [256, 256, 1024], stage=4, block='a') # projection shortcut\n",
    "#     x = identity_block(x, 3, [256, 256, 1024], stage=4, block='b')\n",
    "#     x = identity_block(x, 3, [256, 256, 1024], stage=4, block='c')\n",
    "#     x = identity_block(x, 3, [256, 256, 1024], stage=4, block='d')\n",
    "#     x = identity_block(x, 3, [256, 256, 1024], stage=4, block='e')\n",
    "#     x = identity_block(x, 3, [256, 256, 1024], stage=4, block='f')\n",
    "#     # 1024-d to 2048-d\n",
    "#     x = conv_block(x, 3, [512, 512, 2048], stage=5, block='a')\n",
    "#     x = identity_block(x, 3, [512, 512, 2048], stage=5, block='b')\n",
    "#     x = identity_block(x, 3, [512, 512, 2048], stage=5, block='c')\n",
    "    \n",
    "#     x = conv_block(x, 3, [512, 512, 361], stage=6, block='a')\n",
    "    x = layers.GlobalAveragePooling2D(name='avg_pool')(x)\n",
    "    x = layers.Dense(361, activation='softmax', name='fc1000')(x)\n",
    "#     if include_top:\n",
    "#         x = layers.GlobalAveragePooling2D(name='avg_pool')(x)\n",
    "#         x = layers.Dense(classes, activation='softmax', name='fc1000')(x)\n",
    "#     else:\n",
    "#         if pooling == 'avg':\n",
    "#             x = layers.GlobalAveragePooling2D()(x)\n",
    "#         elif pooling == 'max':\n",
    "#             x = layers.GlobalMaxPooling2D()(x)\n",
    "#         else:\n",
    "#             warnings.warn('The output shape of `ResNet50(include_top=False)` '\n",
    "#                           'has been changed since Keras 2.2.0.')\n",
    "#     x = layers.GlobalAveragePooling2D()(x)\n",
    "    \n",
    "    if input_tensor is not None:\n",
    "        inputs = keras_utils.get_source_inputs(input_tensor)\n",
    "    else:\n",
    "        inputs = img_input\n",
    "        \n",
    "    model = Model(inputs, x, name='resnet50')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "2a66e90d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"resnet50\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_7 (InputLayer)            [(None, 19, 19, 13)] 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2a (Conv2D)         (None, 19, 19, 64)   896         input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2a (BatchNormalizati (None, 19, 19, 64)   256         res2a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_108 (Activation)     (None, 19, 19, 64)   0           bn2a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2b (Conv2D)         (None, 19, 19, 64)   36928       activation_108[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2b (BatchNormalizati (None, 19, 19, 64)   256         res2a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_109 (Activation)     (None, 19, 19, 64)   0           bn2a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2c (Conv2D)         (None, 19, 19, 256)  16640       activation_109[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch1 (Conv2D)          (None, 19, 19, 256)  3584        input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2c (BatchNormalizati (None, 19, 19, 256)  1024        res2a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch1 (BatchNormalizatio (None, 19, 19, 256)  1024        res2a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_36 (Add)                    (None, 19, 19, 256)  0           bn2a_branch2c[0][0]              \n",
      "                                                                 bn2a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_110 (Activation)     (None, 19, 19, 256)  0           add_36[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2a (Conv2D)         (None, 19, 19, 64)   16448       activation_110[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2a (BatchNormalizati (None, 19, 19, 64)   256         res2b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_111 (Activation)     (None, 19, 19, 64)   0           bn2b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2b (Conv2D)         (None, 19, 19, 64)   36928       activation_111[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2b (BatchNormalizati (None, 19, 19, 64)   256         res2b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_112 (Activation)     (None, 19, 19, 64)   0           bn2b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2c (Conv2D)         (None, 19, 19, 256)  16640       activation_112[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2c (BatchNormalizati (None, 19, 19, 256)  1024        res2b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_37 (Add)                    (None, 19, 19, 256)  0           bn2b_branch2c[0][0]              \n",
      "                                                                 activation_110[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_113 (Activation)     (None, 19, 19, 256)  0           add_37[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2a (Conv2D)         (None, 19, 19, 64)   16448       activation_113[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2a (BatchNormalizati (None, 19, 19, 64)   256         res2c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_114 (Activation)     (None, 19, 19, 64)   0           bn2c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2b (Conv2D)         (None, 19, 19, 64)   36928       activation_114[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2b (BatchNormalizati (None, 19, 19, 64)   256         res2c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_115 (Activation)     (None, 19, 19, 64)   0           bn2c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2c (Conv2D)         (None, 19, 19, 256)  16640       activation_115[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2c (BatchNormalizati (None, 19, 19, 256)  1024        res2c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_38 (Add)                    (None, 19, 19, 256)  0           bn2c_branch2c[0][0]              \n",
      "                                                                 activation_113[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_116 (Activation)     (None, 19, 19, 256)  0           add_38[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2a (Conv2D)         (None, 19, 19, 64)   16448       activation_116[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2a (BatchNormalizati (None, 19, 19, 64)   256         res3b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_117 (Activation)     (None, 19, 19, 64)   0           bn3b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2b (Conv2D)         (None, 19, 19, 64)   36928       activation_117[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2b (BatchNormalizati (None, 19, 19, 64)   256         res3b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_118 (Activation)     (None, 19, 19, 64)   0           bn3b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2c (Conv2D)         (None, 19, 19, 256)  16640       activation_118[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2c (BatchNormalizati (None, 19, 19, 256)  1024        res3b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_39 (Add)                    (None, 19, 19, 256)  0           bn3b_branch2c[0][0]              \n",
      "                                                                 activation_116[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_119 (Activation)     (None, 19, 19, 256)  0           add_39[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2a (Conv2D)         (None, 19, 19, 64)   16448       activation_119[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2a (BatchNormalizati (None, 19, 19, 64)   256         res3c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_120 (Activation)     (None, 19, 19, 64)   0           bn3c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2b (Conv2D)         (None, 19, 19, 64)   36928       activation_120[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2b (BatchNormalizati (None, 19, 19, 64)   256         res3c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_121 (Activation)     (None, 19, 19, 64)   0           bn3c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2c (Conv2D)         (None, 19, 19, 256)  16640       activation_121[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2c (BatchNormalizati (None, 19, 19, 256)  1024        res3c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_40 (Add)                    (None, 19, 19, 256)  0           bn3c_branch2c[0][0]              \n",
      "                                                                 activation_119[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_122 (Activation)     (None, 19, 19, 256)  0           add_40[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2a (Conv2D)         (None, 19, 19, 64)   16448       activation_122[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2a (BatchNormalizati (None, 19, 19, 64)   256         res3d_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_123 (Activation)     (None, 19, 19, 64)   0           bn3d_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2b (Conv2D)         (None, 19, 19, 64)   36928       activation_123[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2b (BatchNormalizati (None, 19, 19, 64)   256         res3d_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_124 (Activation)     (None, 19, 19, 64)   0           bn3d_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2c (Conv2D)         (None, 19, 19, 256)  16640       activation_124[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2c (BatchNormalizati (None, 19, 19, 256)  1024        res3d_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_41 (Add)                    (None, 19, 19, 256)  0           bn3d_branch2c[0][0]              \n",
      "                                                                 activation_122[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_125 (Activation)     (None, 19, 19, 256)  0           add_41[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "avg_pool (GlobalAveragePooling2 (None, 256)          0           activation_125[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "fc1000 (Dense)                  (None, 361)          92777       avg_pool[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 511,145\n",
      "Trainable params: 506,025\n",
      "Non-trainable params: 5,120\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = ResNet50(include_top=True,\n",
    "                 input_tensor=None,\n",
    "                 input_shape=(19, 19, 13),\n",
    "                 pooling=False)\n",
    "opt = Adam(learning_rate = 0.0005)\n",
    "model.compile(optimizer = opt,\n",
    "              loss='categorical_crossentropy',\n",
    "                metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "39553a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = load_model('./models/model_kyu_10_14.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4a4d7f1c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    102/Unknown - 14s 123ms/step - loss: 5.7691 - accuracy: 0.0212"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[37], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mval_dataset\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\aicup_\\lib\\site-packages\\keras\\engine\\training.py:1189\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1187\u001b[0m logs \u001b[38;5;241m=\u001b[39m tmp_logs  \u001b[38;5;66;03m# No error, now safe to assign to logs.\u001b[39;00m\n\u001b[0;32m   1188\u001b[0m end_step \u001b[38;5;241m=\u001b[39m step \u001b[38;5;241m+\u001b[39m data_handler\u001b[38;5;241m.\u001b[39mstep_increment\n\u001b[1;32m-> 1189\u001b[0m \u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mon_train_batch_end\u001b[49m\u001b[43m(\u001b[49m\u001b[43mend_step\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1190\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_training:\n\u001b[0;32m   1191\u001b[0m   \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\aicup_\\lib\\site-packages\\keras\\callbacks.py:435\u001b[0m, in \u001b[0;36mCallbackList.on_train_batch_end\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m    428\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Calls the `on_train_batch_end` methods of its callbacks.\u001b[39;00m\n\u001b[0;32m    429\u001b[0m \n\u001b[0;32m    430\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m    431\u001b[0m \u001b[38;5;124;03m    batch: Integer, index of batch within the current epoch.\u001b[39;00m\n\u001b[0;32m    432\u001b[0m \u001b[38;5;124;03m    logs: Dict. Aggregated metric results up until this batch.\u001b[39;00m\n\u001b[0;32m    433\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    434\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_call_train_batch_hooks:\n\u001b[1;32m--> 435\u001b[0m   \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_batch_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mModeKeys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTRAIN\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mend\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\aicup_\\lib\\site-packages\\keras\\callbacks.py:295\u001b[0m, in \u001b[0;36mCallbackList._call_batch_hook\u001b[1;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[0;32m    293\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_batch_begin_hook(mode, batch, logs)\n\u001b[0;32m    294\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m hook \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mend\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m--> 295\u001b[0m   \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_batch_end_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    296\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    297\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUnrecognized hook: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(hook))\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\aicup_\\lib\\site-packages\\keras\\callbacks.py:315\u001b[0m, in \u001b[0;36mCallbackList._call_batch_end_hook\u001b[1;34m(self, mode, batch, logs)\u001b[0m\n\u001b[0;32m    312\u001b[0m   batch_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch_start_time\n\u001b[0;32m    313\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch_times\u001b[38;5;241m.\u001b[39mappend(batch_time)\n\u001b[1;32m--> 315\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_batch_hook_helper\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhook_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch_times) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_batches_for_timing_check:\n\u001b[0;32m    318\u001b[0m   end_hook_name \u001b[38;5;241m=\u001b[39m hook_name\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\aicup_\\lib\\site-packages\\keras\\callbacks.py:353\u001b[0m, in \u001b[0;36mCallbackList._call_batch_hook_helper\u001b[1;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[0;32m    351\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m callback \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallbacks:\n\u001b[0;32m    352\u001b[0m   hook \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(callback, hook_name)\n\u001b[1;32m--> 353\u001b[0m   \u001b[43mhook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    355\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_timing:\n\u001b[0;32m    356\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m hook_name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_hook_times:\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\aicup_\\lib\\site-packages\\keras\\callbacks.py:1028\u001b[0m, in \u001b[0;36mProgbarLogger.on_train_batch_end\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m   1027\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mon_train_batch_end\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch, logs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m-> 1028\u001b[0m   \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_batch_update_progbar\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\aicup_\\lib\\site-packages\\keras\\callbacks.py:1100\u001b[0m, in \u001b[0;36mProgbarLogger._batch_update_progbar\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m   1096\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseen \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m add_seen\n\u001b[0;32m   1098\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   1099\u001b[0m   \u001b[38;5;66;03m# Only block async when verbose = 1.\u001b[39;00m\n\u001b[1;32m-> 1100\u001b[0m   logs \u001b[38;5;241m=\u001b[39m \u001b[43mtf_utils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msync_to_numpy_or_python_type\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1101\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprogbar\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseen, \u001b[38;5;28mlist\u001b[39m(logs\u001b[38;5;241m.\u001b[39mitems()), finalize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\aicup_\\lib\\site-packages\\keras\\utils\\tf_utils.py:516\u001b[0m, in \u001b[0;36msync_to_numpy_or_python_type\u001b[1;34m(tensors)\u001b[0m\n\u001b[0;32m    513\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39mndim(x) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m x\n\u001b[0;32m    514\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m t  \u001b[38;5;66;03m# Don't turn ragged or sparse tensors to NumPy.\u001b[39;00m\n\u001b[1;32m--> 516\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_structure\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_to_single_numpy_or_python_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\aicup_\\lib\\site-packages\\tensorflow\\python\\util\\nest.py:869\u001b[0m, in \u001b[0;36mmap_structure\u001b[1;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[0;32m    865\u001b[0m flat_structure \u001b[38;5;241m=\u001b[39m (flatten(s, expand_composites) \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m structure)\n\u001b[0;32m    866\u001b[0m entries \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mflat_structure)\n\u001b[0;32m    868\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m pack_sequence_as(\n\u001b[1;32m--> 869\u001b[0m     structure[\u001b[38;5;241m0\u001b[39m], [func(\u001b[38;5;241m*\u001b[39mx) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m entries],\n\u001b[0;32m    870\u001b[0m     expand_composites\u001b[38;5;241m=\u001b[39mexpand_composites)\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\aicup_\\lib\\site-packages\\tensorflow\\python\\util\\nest.py:869\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    865\u001b[0m flat_structure \u001b[38;5;241m=\u001b[39m (flatten(s, expand_composites) \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m structure)\n\u001b[0;32m    866\u001b[0m entries \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mflat_structure)\n\u001b[0;32m    868\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m pack_sequence_as(\n\u001b[1;32m--> 869\u001b[0m     structure[\u001b[38;5;241m0\u001b[39m], [\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m entries],\n\u001b[0;32m    870\u001b[0m     expand_composites\u001b[38;5;241m=\u001b[39mexpand_composites)\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\aicup_\\lib\\site-packages\\keras\\utils\\tf_utils.py:512\u001b[0m, in \u001b[0;36msync_to_numpy_or_python_type.<locals>._to_single_numpy_or_python_type\u001b[1;34m(t)\u001b[0m\n\u001b[0;32m    510\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_to_single_numpy_or_python_type\u001b[39m(t):\n\u001b[0;32m    511\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(t, tf\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[1;32m--> 512\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    513\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39mndim(x) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m x\n\u001b[0;32m    514\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m t\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\aicup_\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:1094\u001b[0m, in \u001b[0;36m_EagerTensorBase.numpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1071\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Copy of the contents of this Tensor into a NumPy array or scalar.\u001b[39;00m\n\u001b[0;32m   1072\u001b[0m \n\u001b[0;32m   1073\u001b[0m \u001b[38;5;124;03mUnlike NumPy arrays, Tensors are immutable, so this method has to copy\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1091\u001b[0m \u001b[38;5;124;03m    NumPy dtype.\u001b[39;00m\n\u001b[0;32m   1092\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1093\u001b[0m \u001b[38;5;66;03m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[39;00m\n\u001b[1;32m-> 1094\u001b[0m maybe_arr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m   1095\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m maybe_arr\u001b[38;5;241m.\u001b[39mcopy() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(maybe_arr, np\u001b[38;5;241m.\u001b[39mndarray) \u001b[38;5;28;01melse\u001b[39;00m maybe_arr\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\aicup_\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:1060\u001b[0m, in \u001b[0;36m_EagerTensorBase._numpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1058\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_numpy\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m   1059\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1060\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_numpy_internal\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1061\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m   1062\u001b[0m     six\u001b[38;5;241m.\u001b[39mraise_from(core\u001b[38;5;241m.\u001b[39m_status_to_exception(e\u001b[38;5;241m.\u001b[39mcode, e\u001b[38;5;241m.\u001b[39mmessage), \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    dataset,\n",
    "    epochs = 1,\n",
    "    validation_data = val_dataset\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2aaddf0b",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kenny\\AppData\\Local\\anaconda3\\envs\\aicup_\\lib\\site-packages\\keras\\utils\\generic_utils.py:494: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  warnings.warn('Custom mask layers require a config and must override '\n"
     ]
    }
   ],
   "source": [
    "model.save('./models/model_kyu_1021_resnet.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ee70e090",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95270/95270 [==============================] - 14218s 149ms/step - loss: 2.1785 - accuracy: 0.5050\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    dataset,\n",
    "    epochs = 1,\n",
    "    validation_data = val_dataset\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f913656c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('./models/model_kyu_resnet_1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "90d58cae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95270/95270 [==============================] - 14285s 150ms/step - loss: 2.0121 - accuracy: 0.5265\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    dataset,\n",
    "    epochs = 1,\n",
    "    validation_data = val_dataset\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3dcbe8c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('./models/model_kyu_resnet_2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a834cce7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 8s 188ms/step - loss: 1.8230 - accuracy: 0.5787 - val_loss: 1.9512 - val_accuracy: 0.5478\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    dataset,\n",
    "    epochs = 1,\n",
    "    validation_data = val_dataset\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f436af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('./models/model_kyu_resnet_3.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb78859b",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    dataset,\n",
    "    epochs = 1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b98c3ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('./models/model_kyu_resnet_4.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a850b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    dataset,\n",
    "    epochs = 1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a4f6688",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('./models/model_kyu_10_15_f128_5.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dd7f4fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    dataset,\n",
    "    epochs = 1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33aca136",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('./models/model_kyu_10_15_f128_6.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "990c90e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    dataset,\n",
    "    epochs = 1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32c0e018",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('./models/model_kyu_10_15_f128_7.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d53e1f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    dataset,\n",
    "    epochs = 1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f38557",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('./models/model_kyu_10_15_f128_8.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27ae4d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    dataset,\n",
    "    epochs = 1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "718dcd6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('./models/model_kyu_10_15_f128_9.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f68be49f",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    dataset,\n",
    "    epochs = 1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fde8199",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('./models/model_kyu_10_14_11.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "484be28d",
   "metadata": {},
   "source": [
    "## ALL DONE!\n",
    "\n",
    "For using the model and creating a submission file, follow the notebook **Create Public Upload CSV.ipynb**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f7fafaa",
   "metadata": {},
   "source": [
    "# End of Tutorial\n",
    "\n",
    "You are free to use more modern NN architectures, a better pre-processing, feature extraction methods to achieve much better accuracy!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b34f1db8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
